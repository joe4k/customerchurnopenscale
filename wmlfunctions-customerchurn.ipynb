{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# WML Functions\nIn this notebook, we leverage Watson Machine Learning functions capability which enables you to create an arbitrary Python function and deploy it to scale using Watson Machine Learning service. \n\nIn particular, we would like to create a Python function as a wrapper to a REST API endpoint for a machine learning churn prediction model which is deployed in a different environment. In the scenario we consider, the machine learning model was trained and deployed to a REST endpoint in a Cloud Pak for Data environment. All that we need is the REST endpoint so can create an adequate wrapper function that captures the input/output in a format consistent with what Watson Openscale needs for monitoring the deployed model.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import os, json\nfrom watson_machine_learning_client import WatsonMachineLearningAPIClient\nimport requests"
        }, 
        {
            "source": "# Watson Machine Learning credentials\nIn the next cell, please provide the Watson Machine Learning credentials which you can get by navigating to your IBM Cloud account, finding your Watson Machine Learning service, and clicking on \"Service Credentials\".\n```\nwml_credentials = {\n    \"apikey\": \"########\",\n    \"instance_id\": \"#########\",\n    \"url\": \"##########\"\n}\n```", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "\nwml_credentials = {\n    \"apikey\": \"########\",\n    \"instance_id\": \"############\",\n    \"url\": \"##########\"\n}"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "client = WatsonMachineLearningAPIClient( wml_credentials )"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# List all the models deployed to your Watson Machine Learning instance\nclient.deployments.list()"
        }, 
        {
            "source": "# If you would like to delete any previous deployments, you can use the following command, change this cell type to Code and execute it after providing the deployment_id (from previous step)\nclient.deployments.delete('##########')", 
            "cell_type": "raw", 
            "metadata": {}
        }, 
        {
            "source": "# Create a deployable function\n\nThe basics of creating and deploying functions in Watson Machine Learning are given here:\n- <a href=\"https://dataplatform.cloud.ibm.com/docs/content/analyze-data/ml-deploy-functions.html\" target=\"_blank\" rel=\"noopener noreferrer\">Creating and deploying functions</a>\n- <a href=\"https://dataplatform.cloud.ibm.com/docs/content/analyze-data/ml-functions.html\" target=\"_blank\" rel=\"noopener noreferrer\">Implementation details of deployable functions</a>\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Define the function\n1. Define a Python closure with an inner function named \"score\".\n2. Use default parameters to save your Watson Machine Learning credentials and the model deployment endpoint URL with the deployed function.\n3. Process the canvas data (reshape and normalize) and then send the processed data to the model deployment.\n4. Process the results from the model deployment so the deployed function returns simpler results.\n5. Implement error handling so the function will behave gracefully if there is an error.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Define WML deployment function so it meets the requirements of Watson Openscale for monitoring.\n\nSpecifically, Watson Openscale requires the endpoints to be compatible with the following swagger [implementation](https://aiopenscale-custom-deployement-spec.mybluemix.net/)\nhttps://aiopenscale-custom-deployement-spec.mybluemix.net/#/Deployments/post_v1_deployments__deployment_id__online\n\nRequest Body:\n\n```\n{\n  \"fields\": [\n    \"name\",\n    \"age\",\n    \"position\"\n  ],\n  \"values\": [\n    [\n      \"john\",\n      33,\n      \"engineer\"\n    ],\n    [\n      \"mike\",\n      23,\n      \"student\"\n    ]\n  ]\n}\n```\n\nResponse should match expected format for Watson OpenScale\n```\n{\n  \"fields\": [\n    \"name\",\n    \"age\",\n    \"position\",\n    \"prediction\",\n    \"probability\"\n  ],\n  \"labels\": [\n    \"personal\",\n    \"camping\"\n  ],\n  \"values\": [\n    [\n      \"john\",\n      33,\n      \"engineer\",\n      \"personal\",\n      [\n        0.6744664422398081,\n        0.32553355776019194\n      ]\n    ],\n    [\n      \"mike\",\n      23,\n      \"student\",\n      \"camping\",\n      [\n        0.2794765664946941,\n        0.7205234335053059\n      ]\n    ]\n  ]\n}\n```\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "**In the next section, replace the cp4d_scoring_url and Authorization token with the correct valuess.**\n- **cp4d_scoring_url**: The cp4d_scoring_url is the REST endpoint for the machine learning model you had trained and deployed in the other environment (In our case, the Cloud Pak for Data cluster). \n- **auth_token**: The auth_token is the authroization token generated for accessing the REST endpoint of the trained model in the other environment\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "ai_parms = {}\n\ndef churn_deployable_function( parms=ai_parms ):\n    \n    def score( function_payload ):\n            \n        cp4d_scoring_url = '#######'\n        auth_token = '########'\n\n        try:\n            import requests\n            import json\n            \n            url = cp4d_scoring_url\n            headers = {\n                'Cache-Control': 'no-cache',\n                'Authorization': auth_token,\n                'Content-Type': 'application/json',\n            }\n       \n    \n            fields = function_payload['fields']\n            values = function_payload['values']\n            \n            # Update the fields with prediction and probability entries\n            outputfields = fields.copy()\n            outputfields.extend(['prediction','probability'])\n            \n            \n            alloutputvalues = []\n            for index in range(0,len(values)):\n                data = json.dumps({\"args\":{\"input_json\":[dict(zip(fields, values[index]))]}})\n                \n                print(\"data: \", data)\n                ## This one works fine (note the verify=False parm)\n                response = requests.post(url, headers=headers, data=data, verify=False)\n                \n                # Map response into a json dict\n                response_json = json.loads(response.text)\n                \n                # Make a copy of values list\n                outputvalues = values[index].copy()\n                \n                # Extract the prediction from the response\n                prediction = response_json['result']['predictions'][0]\n                \n                # Extract the probabilities form the response\n                # Note that the probabilities should match the same order of the classes (or labels)\n                probabilities = response_json['result']['probabilities'][0]\n                \n                # Update the values entry with the values for prediction and probabilities\n                outputvalues.extend([prediction,probabilities])\n                \n                alloutputvalues.append(outputvalues)\n                \n                # Extract the labels\n                labels = response_json['result']['classes']\n                \n            final_response = {\"fields\":outputfields, \"labels\":labels, \"values\":alloutputvalues}\n            \n            return final_response\n            \n        except Exception as e:\n            \n            return { \"error\" : repr( e ) }\n\n\n    return score"
        }, 
        {
            "source": "### Test the Function locally\nYou can test your function in the notebook before deploying the function.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "fields = ['LONGDISTANCE', 'INTERNATIONAL', 'LOCAL', 'DROPPED', 'PAYMETHOD', 'LOCALBILLTYPE', 'LONGDISTANCEBILLTYPE', 'USAGE', 'RATEPLAN', 'GENDER', 'STATUS', 'CHILDREN', 'ESTINCOME', 'CAROWNER', 'AGE']\nvalues = [\n    [23, 0, 206, 0, 'CC', 'Budget', 'Intnl_discount', 229, 3, 'F', 'S', 1, 38000.0, 'N', 24.393]\n]\ntest_data = {\n    \"fields\": fields,\n    \"values\": values\n}"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Pass the sample canvas data to the function as a test\nfunc_result = churn_deployable_function()(test_data)\nprint( func_result )"
        }, 
        {
            "source": "### Store and deploy the function to WML\nBefore you can deploy the function, you must store the function in your Watson Machine Learning repository.\n\nProvide a unique name for the deployed function in WML so you can identify and retrieve efficiently.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Store the deployable function in your Watson Machine Learning repository\n# \nmeta_data = { client.repository.FunctionMetaNames.NAME : 'Customer Churn ICP4D labuser1' }\nfunction_details = client.repository.store_function( meta_props=meta_data, function=churn_deployable_function )"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Deploy the stored function\n#\nfunction_id = function_details[\"metadata\"][\"guid\"]\nfunction_deployment_details = client.deployments.create( artifact_uid=function_id, name=\"Customer Churn ICP4D labuser1\" )"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Verify function shows up in the deployments for WML\n# In the listing below, you should see the Name for the model you deployed.\nclient.deployments.list()"
        }, 
        {
            "source": "### Test the deployed function in WML\nYou can use the Watson Machine Learning Python client or REST API to send data to your function deployment for processing in exactly the same way you send data to model deployments for processing.\n\nIn the listing above, you should see the Name of the model you deployed. For that model, extract the deployment_id (first column from list above) and specify it in the next cell.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "deployment_id = '############'"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "function_deployment_details = client.deployments.get_details(deployment_id)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Get the endpoint URL of the function deployment just created\n#\nfunction_deployment_endpoint_url = client.deployments.get_scoring_url( function_deployment_details )\nfunction_deployment_endpoint_url"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Test the WML deployed function\nresult = client.deployments.score( function_deployment_endpoint_url, test_data )\nif \"error\" in result:\n    print( result[\"error\"] )\nelse:\n    print( result )"
        }, 
        {
            "source": "# Conclusion\nWith this notebook, we created a function wrapper to a REST endpoint of a trained machine learning model which is deployed in a different environment and deployed it to Watson Machine Learning on IBM Cloud. This allows us to monitor this machine learning model for accuracy, fairness, drift, and explainability with Watson Openscale.", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}